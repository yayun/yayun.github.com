---
layout: post
title: "《数据密集型应用系统设计》第一部分 数据系统基础 笔记"
---
# 第一章 可靠、可扩展与可维护的应用系统

## 认识数据系统

设计数据系统和数据服务时，一定会碰到很多棘手的问题。例如，当系统内出现了局部失效时，如何确保数据的正确性和完整性？当发生系统降级时，如何为客户提供一致的良好表现？负载增加时，系统如何扩展？友好的服务API该如何设计？

## 可靠性

即使发生了某些错误，系统仍可以继续正常工作。
我们不太可能将故障概率降低为0，因此通常设计容错机制来避免从故障引发系统失效。

**硬件故障**

为硬件添加冗余来减少系统故障率。
只要可以将备份迅速恢复到新机器上，故障的停机时间大多数应用中并不是灾难性的。多机冗余则只对少量的关键应用更有意义，对于这些应用，高可用是绝对必要的。

**软件错误**

软件系统问题有时没有快速解决办法，而只能仔细考虑很多细节，包括认真检查依赖的假设条件与系统之间交互，进行全面的测试，进程隔离，允许进程崩溃并自动重启，反复评估，监控并分析生产环节的行为表现等。

**人为失误**

* 以最小出错的方式来设计系统。如：精心设计的抽象层，使“做正确的事情”很轻松，但搞坏很复杂。如果限制过多，人们会想办法绕过，解决之道在于很好的平衡
* 分离最容易出错的地方。提供一个功能齐全的沙箱环境，必要时导入线上真实数据，在里面放心的尝试体验，万一出现问题不会影响真实用户
* 充分测试
* 详细而清晰的监控子系统
* 推行管理流程并加以培训

## 可扩展性
 
如果系统以某种方式增长，我们应对增长的措施有哪些？我们该如何添加计算资源来处理额外的负载？

**描述负载** 

负载可以用称为负载参数的若干数字来描述。参数的最佳选择取决于系统的体系结构，它可能是 web 服务器每秒请求处理次数，数据库的写入比例，聊天室同时活动用户数量，缓存命中率等。

以 twitter 为例，两个典型的业务场景：

* 用户发布 twitter，将 twitter 推送到所有的关注者，4.6 request/sec 峰值 12k requests/sec
* home timeline，关注者查看关注对象的最新消息，平均 300k requests/sec

有两种处理方案：

1. users 表 + follows 表 + tweets 表；用户发布 tweets 插入到 tweets 表、follows 表存储用户关注关系；当某一个用户查看 timeline 时，查找所有的关注对象列出这些人所有的 tweets，最后以时间为序来排序:

> select tweets.* , users.* from  tweets 
	join users on tweets.sender_id = users.id
	join follows on follows.followee_id = users.id
	where users.follower_id = current_user

2. 对每个用户的 timeline 维护一个缓存，当用户推送新 tweet 时，查询所有的关注者，将 tweet 插入到其所有关注则的 timeline 的缓存中。因为 timeline 的浏览压力比发布 tweet 要高出两个数量级，在发布时多完成一些事情可以加速读性能。

方法2的缺点，考虑到平均 75 个关注者，每秒 4.6 k的 tweet，需要每秒 4.6k * 75 = 345k 的速率写入缓存。关注者偏差大，如果某人有 3k万的 follower 峰值一个 tweet 会有 3k万的写入。优化方案：少数有超多关注者的用户 tweet 单独提取采用类似 1 的方式，在读取时和用户的 timeline 进行合并。

**描述性能**

设想如果负载增加将会发生什么？有两种考虑方式：

* 负载增加，但系统资源（如 CPU 内存 网络带宽等）保持不变，系统性能会发生什么变化？
* 负载增加，如果要保持性能不变，需要增加多少资源

**应对负载增加的方法**

水平扩展和垂直扩展。
好的架构通常要做些实际的取舍，例如，使用几个强悍的服务器仍可以比大量的小型虚拟机来得更简单、便宜。

超大规模的系统往往针对特定的应用高度定制，很难有一种通用的架构。背后的取舍因素包括读取量、写入量、待存储的数据量、数据的复杂度、响应时间要求、访问模式等，更多的是上述所有因素的叠加再加上其他更复杂的问题。

对于早期初创公司或未定型的产品，快速迭代退出产品功能往往比投入精力来应对不可知的扩展性更为重要。

## 可维护性

每一个遗留系统总有其过期的理由，所以很难给出一个通用的建议该如何处理它们。

我们可以在软件设计时考虑尽可能减少维护期间的麻烦，避免造出荣有过期的系统。

软件系统的三个设计原则：

* 可维护性 方便运维团队保持系统平稳运行
* 简单性 简化系统复杂性 新工程师可以轻松理解系统
* 可演化性 后续工程师可以轻松的对系统进行改进，并根据需求变化将其适配到非典型场景，

**可运维性**

一个优秀的运行团队负责的内容

数据系统设计可以贡献的：

* 提供监控
* 支持自动化 与标准工具集成
* 避免绑定具体的机器 
* 提供良好的文档和易于理解的操作模式
* 提供良好的默认配置允许管理员需要时方便的修改默认值
* 尝试自我修复 需要时让管理员手动控制系统状态
* 行为可预测 减少意外发生

**简单性：简化复杂度**

复杂性有各种各样的表现形式：状态空间的膨胀，模块紧耦合，令人纠结的相互依赖关系，不一致的命名和术语，为了性能而采取的特殊处理，为解决某特定问题而引入的特殊框架等。

消除意外复杂性的最好的手段之一是抽象。一个好的设计抽象可以隐藏大量的实现细节，并对外提供干净、易懂的接口。

**可演化性 易于改变**

简单易懂的系统往往比复杂的系统更容易修改。


# 第二章 数据模型与查询语言


大多数应用程序是通过一层一层叠加数据模型来构建的。每一层都面临的关键问题是：如何将其用下一层表示？例如：

1. 应用程序开发人员，观测现实世界，通过对象或数据结构以及操作这些数据结构的 api 对其进行建模。这些数据结构往往特定于该应用。
2. 当需要存储这些数据结构时，可以采用通用数据模型来表示
3. 数据库工程师接着决定用何种内存 磁盘或网络字节格式来表示上述 json/xml/关系/图形数据。数据需要支持多种方式的查询 搜索 操作和处理数据
4. 在更下一层，硬件工程师则需要考虑用电流 光脉冲 磁场等来表示字节

每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。

考虑到数据模型对其上的软件应用有着巨大的影响（哪些能做哪些不能），因此需要慎重选择合适的数据模型。


> 数据模型分成三类：层次模型、网状模型、关系模型
> 
> * 关系模型的基本假设是所有数据都表示为数学上的关系。基本的关系
> 造块是域或者叫数据类型。关系模型是第一个形式化的数据库模型。
> * 层次模型 用树形结构描述实体及其之间关系的数据模型。只能处理一对多的实体联系
> * 网状模型 层次模型使用树形结构来表示实体及实体间的关系，每一个结点表示一个记录，除了根节点外每一个节点都有且仅有一个双亲结点，但可以有多个子节点。但是网状模型允许一个结点可以同时拥有多个双亲结点和子节点。因而同层次模型相比，网状结构更具有普遍性，能够直接地描述现实世界的实体。也可以认为层次模型是网状模型的一个特例。
> 
> [关系模型 wiki](https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B)


## 关系模型与文档模型

现在最著名的数据模型可能是 SQL，它基于关系模型：数据被组织成关系，在 sql 中称为表。
当前网上看到的大部分内容很多仍然是由关系数据库支撑

### NoSQL 的诞生

> NoSQL（最初表示Non-SQL，后来有人转解为Not only SQL），是对不同于传统的关系数据库的数据库管理系统的统称。包含文档存储，图数据库，键值存储，主机服务，多数据库，时序性数据库，对象数据库，列存储。
> 
> [NoSQL wiki](https://zh.wikipedia.org/wiki/NoSQL#%E6%97%B6%E5%BA%8F%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93)

“NoSQL” 这个名字是不恰当的，它其实并不代表具体的某些技术，它最初只是最为一个吸引人眼球的 twitter 标签频频出现在 2009 年开源、分布式以及非关系数据库的见面会上。

采用 NoSQl 数据库的几个驱动因素：

* 比关系数据库更好的扩展需求 支持超大数据集或超高的写入吞吐
* 普遍偏爱免费和开源软件
* 关系模型不能很好的支持一些特定的查询操作
* 对关系模式一些限制性感到沮丧，渴望更具动态和表达力的数据模型

可预见的未来，关系数据库和各种非关系数据库存储一起使用。

###  对象关系不匹配

现在大多数应用开发都采用面向对象编程语言，由于兼容性问题，普遍对 sql 数据模型存在抱怨：如果数据存在关系表中，那么应用代码层中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层。（一些 ORM 框架减少了此转换层所需的样板代码量，但是他们并不能完全隐藏两个模型之间的差异）

以简历为例，用关系模式来表示

<img src="/images/jianli-relation.png">

因为一个人职业经历中有一个以上的工作，并且有多段教育阶段和任意数量的联系方式，用户和这些事一对多的关系：

* 如上图，放在单独的表中 使用外键
* sql 标准也增加了对结构化数据类型和 XML 数据的支持，允许将多值存储在单行内，并支持文档中的查询和检索。（IBM DB2，MySQL，PostgreSQL 在不同程度上支持这种功能，但是貌似性能不是很好？）
* 将工作 教育信息 联系方式以 json 的形式放在 数据库的文本列中。

另一种方式是直接使用 json 模式，所有的关系信息都在一个地方，进行一次查询就足够了，json 将树状结构显示化。

###  多对一与多对多的关系

在关系数据库中，类似 region_id industry_id 定义为 ID，而不是纯文本字符串的形式。如果用户界面是可以输入地区或行业的自由文本字段，存为文本字符串更有意义。但是拥有地理区域和行业的标准化列表，并让用户从下拉列表或者自动填充器中进行选择会更有优势。

存储为 ID 的好处是因为其对人类没有任何直接意义永远不需要直接修改，即使 ID 标识的信息发生变化。所有对人类有意义的东西都可能在某时发生变更。如果这些信息被复制，那么所有冗余副本都需要更新，会导致更多的写入开销，并且存在数据不一致风险。消除这种重复正式数据库规范化的核心思想。

关系数据库中很容易表示这种多对一的关系（许多人在同一个地区生活 同一行业工作），但是文档模型却适用。

如果数据库不支持则需要在应用程序代码中通过对数据库进行多次查询来模拟联结。（对于上述例子 地区和行业的列表很小且在一段时间内不太可能发生变化，应用程序可以简单的将其缓存在内存。但无论如何联结的工作其实从数据库转移到了应用层）。

即使应用程序初始版本非常适合无联结的文档模式，但随着应用支持越来越多的功能，数据也变得更加互联一体化。我们可以根据具体的功能对文档数据库进行扩充，在文档内的数据添加一些引用，并在查询时需要联结操作。

###  文档数据库是否在重演历史？

IBM 信息管理系统采用了相当简单的数据模型，层次模型。与 json 有显著的相似之处，所有的数据表示为嵌套在记录中的记录树。与文档数据库类似，可以很好的支持一对多的关系但支持多对多有些困难，不支持联结。开发人员需要自己决定是复制多份数据还是在代码层手动解析数据，和现在我们使用文档数据库遇到的问题类似。

为了解决层次模式局限性，提出了多种解决方案，最著名的是关系模型（演变成 sql）和网状模型。

*网状模型*

层次模型每个记录只有一个点，网状模型中 一个记录可能有多个父节点。

*关系模型*

定义了所有数据的格式：关系（表）只是元组（行）的集合。没有复杂的嵌套结构也没有复杂的访问路径。可以读取表中的任何一行或者所有行，支持任意条件的查询。

查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些选择实际上等价于“访问路径”，但最大的区别在于他们是由查询优化器自动生成而不是开发人员维护。

如果想使用新方式查询数据只需声明一个新的索引，查询会自动使用最合适的索引。

*文档数据库比较*

文档数据库是某种方式的层次模型：父记录中保存了嵌套记录，而不是存储在单独的表中。

但是在表示多对一和多对多关系时，关系数据库和文档数据库没有根本的不同：相关项由唯一的标志符引用，该标志符在关系模型中称为外键，在文档模型中称为文档引用。

###  关系数据库和文档数据库的现状

文档数据模型主要论点是模式灵活性，由于局部性带来的较好的性能，但对于某些应用来说，更接近于应用程序所使用的数据结构。关系模型强在联结操作、多对一和多对多关系更简洁的表达上。

*哪种数据模型的应用代码更简单*

无法一概而论哪种数据模型的应用代码更简单。主要取决于数据项之间的关系类型。

*文档模型中的模式灵活性*

读时模式（数据的结构是隐式的，只有读取时才解释）
写时模式（关系数据库的一种传统方法，模式是显式的，并且数据库确保数据写入时都必须遵循）

如果集合中的项由于某种原因，并不具有相同的结构：

* 有很多不同类型的对象，将这些对象都保存在各自的表中不太现实
* 数据的结构由无法控制的外部系统所决定，且随时改变

这些情况下，模式带来的损害大于它能提供的帮助。

*查询的数据局部性*

局部性优势仅适用于同时访问文档大部分内容的场景。

*文档数据库与关系数据库的融合*

## 数据查询语言

SQL 是一种声明式查询语言，IMS 和 CODASYL 是命令式的。

命令式：

	function getSharks(){
		var sharks =[];
		for(var i =0; i < animals.length; i++){
			if(animals[i].family ==="Sharks"){
            sharks.push(animals[i]);
			}
		}
		return sharks;
	}

在关系代数中：sharks = σ_{family = “sharks”}(animals)σ（希腊字母西格玛）是选择操作符

声明式 （遵循关系代数）

	SELECT * FROM animals WHERE family ='Sharks';

声明式隐藏了数据库引擎的很多实现细节，这样数据库可以在不改变查询语句的情况下提高性能。

### Web 上的声明式查询

Web 浏览器的例子，使用声明式 CSS 样式比用 js 命令式的操作样式要好得多。

### MapReduce 查询

既不是声明式也不是命令式，而是介于两者之间。

## 图状数据模型。

### 属性图

* 任何顶点都可以连接到其他任何顶点。没有模式可以限制哪种事物可以或不可以关联
* 给定某个顶点，可以高效的得到它的所有入边和出边
* 通过对不同类型的关系使用不同的标签，可以在单个图中存储不同类型的信息，任然保持整洁的数据模型

### Cypher查询语言

声明式查询语言

### SQL 中图查询

可以采用关系数据库表示图数据。
有一些困难。

### 三元存储与SPARQL

三元存储模式几乎等同于属性图模型，只是使用不同的名次描述了相同的思想。

*语义网*

*RDF数据模型*

*SPARQL 查询语言*

一种采用 RDF 数据模型的三元存储查询语言。

### Datalog 基础

类似三元存储模式但更为通用一些。

## 小结

数据最初被表示为一颗大树（层次模型），但不利于多对多关系，所以发明关系模型来解决这个问题。最近开发人员发现一些应用程序也不太适合关系模型。新的非关系 NoSQL 数据存储在两个主要方向上存在分歧：

1. 文档数据库的目标用例是来自于包含文档，且一个文档与其他文档之间的关联很少。
2. 图数据库则针对相反的场景，目标是所有数据都可能会互相关联。

文档数据库和图数据库有一个共同点：通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化需求。

每个数据模型都有自己的查询语言或框架。

下一章，将继续讨论在实现本章所描述的数据模型过程中有哪些重要的权衡设计。


# 第三章 数据检存储与检索

上一章讨论了数据模型和查询语言：应用开发人员向数据库指明数据格式并在之后如何查询的机制。本章从数据库的角度来探讨同样的问题：如何存储输入的数据，并在收到查询请求时，怎样重新找到数据。

存储引擎：针对事物型工作负载的和针对分析型的存储引擎

这些存储引擎用于传统的关系数据库和大多数所谓的 NoSQL 数据库

两个存储引擎家族：日志结构的存储引擎和面向页的存储引擎如 B-tree

## 数据库的核心：数据结构

一个简单的数据库实现：仅支持 *db_get* 和 *db_get*，底层存储是一个村文本文件，每行包含一个 key-value 对，用逗号分隔。每次调用 db_set 追加新内容到文件末尾，如果多次更新某个键，旧版本值不会被覆盖，而是需要查看文件中最后一次出现的键来找到最新的值（ *db_get* 中使用 tail -n 1）。

许多数据库内部都使用日志，日志仅支持追加式更新数据文件。如果日志保存大量记录，db_get 性能会很差，查找开销是 O(n).

为了高效的查找数据库中特定键的值，需要新的数据结构：索引

索引是基于原始数据派生而来的额外数据结构。由于每次写入都需要更新索引，因此任何类型的索引都会降低写的速度。

存储系统中重要的权衡设计：适当的索引可以加速读取查询，但每个索引都会减慢写速度。

### 哈希索引

数据存储全部采用追加式文件组成。索引策略：保存内存中的 hash map，把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。每当在文件中追加新的 key-value 对时，还需要更新 hash map 来反映刚刚写入数据的偏移量（包括插入新的键和更新已有的键，已有的键用最新的偏移量来更新）。

这是 Bitcask（Riak 的默认引擎）所采用的核心做法。Bitcask 可以提供高性能的读和写，只要所有的 key 可以放入内存（hash map 需要保存在内存中）。value 的数据量可以超过内存大小，只需一次磁盘寻址就可以将 value 从磁盘加载到内存，如果那部分数据文件已经在文件系统缓存中，则读取根本不需要任何的磁盘 I/O。

Bitcask 适合每个键的值频繁更新的场景。eg：key 是视频 URL，value 是播放次数。此种场景有很多写操作，没有太多不同的 key，所以将 key 保存在内存中是可行的。

只追加到一个文件，文件越来越大 压缩的方式：

将日志分解成一定大小的段，当文件打到一定大小时就关闭它，并将后续写入到新的段文件中。然后在这些段上执行压缩。

如果有多个段，每个段都有自己的 hashmap，检查时首先检查最新的段的 hash map，如果键不存在，检查第二最新的段，以此类推。由于合并过程可以维持较少的段数量，因此查找通常不需要检查很多的 hashmap。

<img src="/images/3-3.png">

需要考虑的几个问题

* 文件格式  csv 不是最佳格式，更快更简单的是使用二进制
* 删除数据 在数据文件中追加一个特殊的删除标示
* 崩溃恢复  从头到尾扫描文件来恢复 hashmap 或者将每个段的 hashmap 存储到磁盘上
* 部分写入的记录  数据库可能会随时崩溃，包括将记录追加到日志的过程中。Bitcask 文件包括校验值，这样可以发现损坏部分并丢弃
* 并发控制  只有一个写线程 数据文件段是追加的并且是不变的，可以被多个线程同时读取

局限性

* hash 表必须全部放入内存，有大量的键就没那么幸运了。如果放在磁盘上，需要大量的随机访问 I/O。
* 区间查询效率不高。


### SSTables 和 LSM-Tree

按照上节的方式，key-value 对的顺序按键排序。叫做排序字符串表，简称 SSTable。它要求每个键在每个合并的段文件中只能出现一次（压缩的过程已经确保，合并的段包含最新的键的值）。

SSTable 相比 hash 索引的优点：

1. 合并段更加高效，因为每个需要合并的段都是已经拍好序的，只需并发读取多个输入段文件，比较每个文件的第一个键把最小的键 copy 到输出文件并重复这个过程。
相同的键有可能存在多个输入段中，因为每个段在某段时间内写入数据库的所有值。这意味着一个输入段中的所有值肯定比其他段中的所有值更新，当多个段包含相同的键时，可以保留最新段的值。并丢弃旧段的值。

2. 在文件查找特定的键时，不再需要在内存中保存所有键的索引。如下图，如果需要查找 handiwork 的值，且不知道该键在段文件中的确切偏移，但如果知道 handbag 和 handsome 的偏移量，考虑到根据键排序，则 handiwork 一定位于它们两者之间。
所以仍然需要一个内存索引来记录某些键的偏移，但它可以是稀疏的，由于可以很快扫描几千字节，对于段文件中的每几千个字节，只需要一个键就足够了。

3. 由于读请求往往需要扫描请求范围内的多个 key-value 对，所以可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩。然后稀疏内存索引的每个条目指向压缩块的开头。除了节省磁盘空间，压缩还减少了 I/O 带宽的占用

<img src="/images/3-5-sstable.png">


*构建和维护SSTables*

存储引擎的基本工作流程：

* 当写入时，将其添加到内存中的平衡树数据结构中。这个内存中的树有时被称为内存表。
* 当内存表大于某个阀值时，将其作为 SSTable 文件写入磁盘。由于树已经维护了按键排序的 key-value 对，写磁盘可以比较高效。新的 SSTable 成为数据库的最新部分。当 SSTable 写磁盘的同时，写入可以继续添加到一个新的内存表实例。
* 处理请求：首先尝试在内存表中查找键，然后是最新的磁盘文件，接下来是次新的磁盘段文件，以此类推，直到找到目标。
* 后台进程周期性的执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被删除或覆盖的值

为了避免数据崩溃，内存表中的数据丢失：在磁盘上保留单独的日志，每个写入都会立即追加到该日志，每当内存表中的数据写入磁盘，相应的日志可以丢弃。

*从SSTables 到 LSM-Tree*

上述算法的本质正是 LevelDB 和 RocksDB 所使用的。最初这个索引结构由 Patrik O'Neil 等人以日志结构的合并树（Log-Structured Merge-Tree 或 LSM-Tree） 命名。基于合并和压缩排序文件原理的存储引擎通常都被称为 LSM 存储引擎。

全文索引比 key-value 索引复杂的多，但它基于类似的想法：给定搜索查询中的某个单词，找到提及该单词的所有文档（网页、产品描述等）。它主要采用 key-value 结构实现，其中键是单词，值是包含该单词的文档 ID 的列表。在 Lucene 中，从词条到 posting list 的映射关系保存在类 SSTable 的排序文件中，这些文件可以根据需要在后台合并。

*性能优化*

在查找数据库中某个不存在的键时，LSM-Tree 算法可能很慢。使用布隆过滤器来判断某个键在不在集合内，如果不在集合内就不需要查找数据库了。

两种不同的压缩策略：（LevleDB 和 RocksDB 使用分层压缩，HBase 使用大小分级，Cassandra 同时支持这两种压缩）

* 大小分级 较新的和较小的 SSTables 被连续合并到较旧和较大的 SSTables
* 分级压缩 键的范围分裂成多个更小的 SSTables，旧数据被移动到单独的 层级


即使数据集远远大于可用内存，仍然能正常工作，由于数据按排序存储，因此可以有效的执行区间查询。

### B-trees

与 SSTables 一样，B-tree 保留按键排序的 key-value 对，这样可以实现高效的 key-value 查找和区间查找。但相似仅此而已：B-tree 本质上具有非常不同的设计理念。

B-tree 将数据库分解成固定大小的块或页（4KB 或更大），页是内部读/写的最小单元。

每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，类似指针，不过是指向磁盘地址而不是内存。可以使用这些页面引用来构造一个树状页面。某一页被指定为 B-tree 的根；每当找到索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

<img src="/images/3-6.png">

B-tree 中一个页所包含的子页引用数量称为分支因子。分支因素取决于存储页面引用和范围边界所需的空间总量，通常为几百个。

B-tree 的数据更新：

* 值的更新：首先搜索包含该键的叶子页，更改该页的值，并将页写回到磁盘
* 添加新键，找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页也需要更新以包含分裂之后的新的键的范围。

<img src="/images/3-7.png">

该算法确保树保持平衡：具有n个键的B-tree 总是具有 O（logn）的深度。大多数数据库可以适合3-4层的B-tree，因此不需要遍历非常深的页面层次即可找到所需的页（分支因子为500的4Kb的四级树可以存储高达256TB）


*使 b-tree 可靠*

B-tree 原地更改数据，LSM-tree 仅追加更新文件，不会修改文件。

某些操作需要覆盖多个页。eg：如果插入导致页溢出，因而需分裂页，那么需要写两个分裂的页，并覆盖其父页以更新对两个子页的引用。如果数据库在完成部分页写入之后发生崩溃，最终回导致索引破坏。

崩溃恢复：使用预写日志（write-ahead-log WAL），也叫重做日志。这是一个仅支持追加修改的文件，每个B-tree 的修改必须先更新 WAL然后再修改树本身。

原地更新页，要注意并发控制，否则线程可能会看到树处于不一致的状态。通常使用锁存器（轻量级的锁）保护树的数据结构来完成。

*优化 b-tree*

* 一些数据库不使用原地覆盖页和 WAL 来进行崩溃恢复而是使用写时复制。
* 保存键的缩略而不是完整的键，只需要提供足够的信息来描述键的启止范围，这样可以将更多的键压入到页中。让树有更高的分支因子。（键的值在最底层的叶子节点上）。这种变种被称为 B+ tree
* 

### 对比 B-tree 和 LSM-tree

### 其他索引结构

## 事务处理与分析处理

### 数据仓库

### 星型与雪花型分析模式

## 列式存储

## 小结






问题：

* 在描述性能那块，服务器并行处理的请求有限（cpu 核数），正在处理的少数请求可能会阻挡后续请求，队头阻塞

	



 


